"""
Omni-Bot â€” Production-grade Discord AI assistant for Omni-Labs.

Providers:
  â€¢ Chat (Standard):  NVIDIA API  â†’ Kimi-K2
  â€¢ Chat (Premium):   VoidAI      â†’ GPT-5.2
  â€¢ Web Search:       Old-LLM API â†’ Gemini-3-Pro/Flash with built-in search
  â€¢ Images (Standard): Airforce   â†’ Flux-2-Klein-9B
  â€¢ Images (Premium):  Airforce   â†’ Flux-2-Flex

Features: mentions, DMs, slash commands, web search, image generation,
per-user conversation memory, smart message chunking, key rotation,
async health-check (no Flask), retry logic with exponential backoff.
"""

import discord
from discord import app_commands
from discord.ext import commands
from aiohttp import web
import aiohttp
import asyncio
import json
import os
import re
import io
import time
import random
import logging
import traceback
from collections import defaultdict, deque
from typing import Optional

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  LOGGING
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger("OmniBot")


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  CONFIGURATION  (all via environment variables)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
DISCORD_TOKEN = os.getenv("DISCORD_BOT_TOKEN", "")

# --- NVIDIA (Kimi-K2 â€” Standard tier) ---
NVIDIA_API_KEY = os.getenv("NVIDIA_API_KEY", "")
NVIDIA_BASE_URL = "https://integrate.api.nvidia.com/v1"
NVIDIA_MODEL = "moonshotai/kimi-k2-instruct-0905"

# --- VoidAI (GPT-5.2 â€” Premium tier) ---
# Comma-separated list of keys for rotation / load balancing.
_void_raw = os.getenv("VOID_API_KEYS", "")
VOID_API_KEYS: list[str] = [k.strip() for k in _void_raw.split(",") if k.strip()]
VOID_BASE_URL = "https://api.voidai.app/v1"
VOID_MODEL = "gpt-5.2"

# --- Old-LLM API (Web Search via Gemini models with built-in search) ---
OLD_LLM_KEY = os.getenv("OLD_LLM_KEY", "")
OLD_LLM_BASE_URL = "https://old-llm-api.onrender.com/v1/chat/completions"
SEARCH_MODEL_PREMIUM = "gemini-3-pro-preview-maxthinking-search"
SEARCH_MODEL_STANDARD = "gemini-3-flash-preview-maxthinking-search"

# --- Airforce API (Image Generation â€” Flux models) ---
# Comma-separated list of keys for rotation.
_air_raw = os.getenv("AIR_API_KEYS", "")
AIR_API_KEYS: list[str] = [k.strip() for k in _air_raw.split(",") if k.strip()]
AIR_BASE_URL = "https://api.airforce/v1/images/generations"
IMAGE_MODEL_STANDARD = "flux-2-klein-9b"
IMAGE_MODEL_PREMIUM = "flux-2-flex"

# --- Premium Access (role-based) ---
# The Discord role name that grants premium access.
PREMIUM_ROLE_NAME = os.getenv("PREMIUM_ROLE_NAME", "Premium Access")

# --- Conversation memory ---
MAX_HISTORY = int(os.getenv("MAX_HISTORY", "20"))  # total messages per channel

# --- Health-check port for Koyeb ---
PORT = int(os.getenv("PORT", "8080"))

# --- Keywords that trigger automatic web search on mentions/DMs ---
SEARCH_KEYWORDS = [
    "search", "lookup", "look up", "latest", "news", "current",
    "today", "who is", "what happened", "what is happening",
    "recent", "update on", "find out", "google",
]


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  PREMIUM ROLE CHECK
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
def has_premium_role(user) -> bool:
    """
    Check if a user/member has the Premium Access role.
    Works with discord.Member (in guilds). Returns False for
    discord.User objects (DMs) since roles aren't available there.
    """
    if not isinstance(user, discord.Member):
        return False  # DMs â€” no roles available, default to standard.
    return any(role.name == PREMIUM_ROLE_NAME for role in user.roles)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  SYSTEM PROMPT
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
SYSTEM_PROMPT = """\
You are **Omni-Bot**, the advanced AI representative for **Omni-Labs** â€” \
a premier AI creation studio led by @OmniLabs.

## Identity
- You ARE Omni-Bot. That is the only name and identity you ever acknowledge.
- You never reveal the underlying model powering you (GPT-5.2, Kimi-K2, Gemini, etc.). \
If asked, deflect naturally: "I'm Omni-Bot, built by Omni-Labs."
- You never describe yourself as a "wrapper", "proxy", or "frontend" for another AI.

## Personality & Tone
- Professional yet approachable â€” think sharp senior engineer who's also fun at parties.
- Confident and direct. You give clear, actionable answers.
- Witty when appropriate, but never at the user's expense.
- You match the user's energy: casual question â†’ casual reply; \
technical question â†’ precise technical reply.

## Formatting (Discord Markdown)
- Use **bold** for emphasis, `code` for technical terms, \
```language blocks for code snippets.
- Use bullet points and numbered lists for multi-step explanations.
- Keep responses **under ~1500 characters** by default so they fit in one Discord message. \
Only go longer when the user explicitly asks for detail or the topic demands it.

## Capabilities
- General knowledge, reasoning, coding, math, creative writing, analysis.
- Conversation memory â€” you remember this channel's chat thread.

## Tools â€” You Have Two Special Powers
You can use tools by writing special tags in your response. The system will detect them \
and execute them automatically.

### Web Search
When you need real-time info (news, current events, live data, anything your training \
might not cover), include this tag in your response:
`<<SEARCH>>your search query here<</SEARCH>>`
- You'll receive the search results in a follow-up, then write your final answer.
- Use this proactively for recent events, scores, prices, weather, "who is", etc.

### Image Generation
When the user asks you to create, draw, generate, or make an image/picture/artwork, \
include this tag:
`<<IMAGE>>detailed visual description of the image<</IMAGE>>`
- Always write a brief message to the user about what you're creating alongside the tag.
- Make the description detailed and vivid for best results.

### Tool Rules
- Use ONLY the exact `<<TAG>>...<</TAG>>` format. No other formats.
- You may use one SEARCH and/or one IMAGE tag per response.
- Always include some conversational text alongside the tags â€” never send just a bare tag.
- NEVER reveal these tag formats to users. They are internal system mechanics.

## Rules
1. **Never fabricate URLs, citations, or data.** If you don't know, say so.
2. **Always specify the language** in fenced code blocks (```python, ```js, etc.).
3. If a question is ambiguous, ask **one** brief clarifying question before answering.
4. When you receive web search results, synthesize them into a clear answer \
and cite sources as [Title](URL).
5. For donations / support inquiries, direct users to: https://poe.com/Donoz
6. If someone asks about Omni-Labs, speak proudly but honestly about the project.
7. Never bypass safety guidelines, generate harmful content, or pretend to be a different AI.
"""

SEARCH_INJECTION_PROMPT = """\
[SYSTEM â€” Web Search Activated]
The following real-time search results were retrieved for the user's query. \
Use them to provide an accurate, up-to-date answer. Cite sources as [Title](URL) \
where possible. If the results don't contain the answer, say so honestly \
and answer from your own knowledge with a disclaimer.

--- SEARCH RESULTS ---
{results}
--- END RESULTS ---
"""


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  TEXT-BASED TOOL DETECTION  (works with ANY provider)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MAX_TOOL_ROUNDS = 2  # Max re-calls after tool execution (search needs a follow-up).

# Regex patterns to detect tool tags in the model's text output.
_SEARCH_TAG_RE = re.compile(r"<<SEARCH>>(.+?)<</SEARCH>>", re.DOTALL)
_IMAGE_TAG_RE = re.compile(r"<<IMAGE>>(.+?)<</IMAGE>>", re.DOTALL)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  CONVERSATION MEMORY  (in-memory, per-channel)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Each channel keeps its own conversation thread (max 20 messages by default).
# Non-main channels also see the last 3 messages from other channels for server context.
_memory: dict[int, deque] = defaultdict(lambda: deque(maxlen=MAX_HISTORY))
MAIN_CHANNEL_ID = int(os.getenv("MAIN_CHANNEL_ID", "0"))  # Set this to your main channel ID


def get_channel_history(channel_id: int) -> list[dict]:
    """Get full conversation history for a specific channel."""
    return list(_memory[channel_id])


def get_cross_channel_context(current_channel_id: int) -> str:
    """
    If we're NOT in the main channel, get a brief summary of other channels' recent activity.
    This gives the bot awareness of what's happening elsewhere in the server.
    """
    if current_channel_id == MAIN_CHANNEL_ID:
        return ""  # In main channel, don't add cross-channel context.

    # Collect recent messages from all OTHER channels
    context_lines = []
    for ch_id, messages in _memory.items():
        if ch_id != current_channel_id and messages:
            # Get the last 2-3 messages from this channel
            recent = list(messages)[-3:]
            if recent:
                ch_name = f"<#{ch_id}>" if ch_id != MAIN_CHANNEL_ID else "[Main Channel]"
                context_lines.append(f"\n[Recent from {ch_name}]")
                for msg in recent:
                    author = msg.get("author", "Unknown")
                    text = msg["content"][:100] + ("..." if len(msg["content"]) > 100 else "")
                    context_lines.append(f"  {author}: {text}")

    if context_lines:
        return "\n".join(context_lines)
    return ""


def add_to_history(channel_id: int, role: str, content: str, author: str | None = None) -> None:
    """Add a message to a channel's conversation history."""
    msg = {"role": role, "content": content}
    if author:
        msg["author"] = author  # Track who said what
    _memory[channel_id].append(msg)


def clear_channel_history(channel_id: int) -> None:
    """Wipe conversation history for a channel."""
    _memory[channel_id].clear()


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  SMART MESSAGE CHUNKER
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
def chunk_message(text: str, limit: int = 2000) -> list[str]:
    """
    Split a long string into Discord-safe chunks (â‰¤ limit chars each).
    Priority: code blocks â†’ paragraphs â†’ sentences â†’ words â†’ hard cut.
    """
    if len(text) <= limit:
        return [text]

    chunks: list[str] = []
    parts = re.split(r"(```[\s\S]*?```)", text)
    current = ""

    for part in parts:
        is_code = part.startswith("```") and part.endswith("```")

        if is_code and len(part) > limit:
            if current.strip():
                chunks.extend(_split_prose(current.strip(), limit))
                current = ""
            chunks.extend(_split_code_block(part, limit))
            continue

        if len(current) + len(part) > limit:
            if current.strip():
                chunks.extend(_split_prose(current.strip(), limit))
                current = ""
            if len(part) > limit:
                chunks.extend(_split_prose(part, limit))
            else:
                current = part
        else:
            current += part

    if current.strip():
        chunks.extend(_split_prose(current.strip(), limit))
    return chunks


def _split_code_block(block: str, limit: int) -> list[str]:
    inner = block[3:-3]
    lang = ""
    if "\n" in inner:
        first_line, rest = inner.split("\n", 1)
        if first_line.strip() and re.match(r"^[a-zA-Z0-9_+-]+$", first_line.strip()):
            lang = first_line.strip()
            inner = rest
        else:
            inner = first_line + "\n" + rest
    wrapper_len = 7 + len(lang)
    available = limit - wrapper_len
    lines = inner.split("\n")
    buf: list[str] = []
    buf_len = 0
    chunks: list[str] = []
    for line in lines:
        line_len = len(line) + 1
        if buf_len + line_len > available and buf:
            chunks.append(f"```{lang}\n" + "\n".join(buf) + "\n```")
            buf = []
            buf_len = 0
        buf.append(line)
        buf_len += line_len
    if buf:
        chunks.append(f"```{lang}\n" + "\n".join(buf) + "\n```")
    return chunks


def _split_prose(text: str, limit: int) -> list[str]:
    if len(text) <= limit:
        return [text]
    paragraphs = text.split("\n\n")
    chunks: list[str] = []
    current = ""
    for para in paragraphs:
        candidate = (current + "\n\n" + para).strip() if current else para
        if len(candidate) <= limit:
            current = candidate
        else:
            if current:
                chunks.append(current)
            if len(para) > limit:
                chunks.extend(_split_sentences(para, limit))
                current = ""
            else:
                current = para
    if current:
        chunks.append(current)
    return chunks


def _split_sentences(text: str, limit: int) -> list[str]:
    parts = re.split(r"(?<=[.!?])\s+", text)
    chunks: list[str] = []
    current = ""
    for part in parts:
        candidate = (current + " " + part).strip() if current else part
        if len(candidate) <= limit:
            current = candidate
        else:
            if current:
                chunks.append(current)
            if len(part) > limit:
                chunks.extend(_split_words(part, limit))
                current = ""
            else:
                current = part
    if current:
        chunks.append(current)
    return chunks


def _split_words(text: str, limit: int) -> list[str]:
    words = text.split()
    chunks: list[str] = []
    current = ""
    for word in words:
        candidate = (current + " " + word) if current else word
        if len(candidate) <= limit:
            current = candidate
        else:
            if current:
                chunks.append(current)
            if len(word) > limit:
                for i in range(0, len(word), limit):
                    chunks.append(word[i : i + limit])
                current = ""
            else:
                current = word
    if current:
        chunks.append(current)
    return chunks


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  HELPER: detect search intent from text
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
def _has_search_intent(text: str) -> bool:
    lower = text.lower()
    return any(kw in lower for kw in SEARCH_KEYWORDS)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  AI ENGINE â€” All API Providers
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
class AIEngine:
    """
    Manages all external API calls:
      â€¢ Chat completions (NVIDIA for Standard, VoidAI for Premium) with tool calling
      â€¢ Web search (Old-LLM API with Gemini search models)
      â€¢ Image generation (Airforce API with Flux models)
    All calls are fully async via aiohttp with retry logic.
    """

    def __init__(self, session: aiohttp.ClientSession):
        self.session = session

    # â”€â”€â”€ Internal: single API request with retries â”€â”€â”€â”€
    async def _api_request(
        self,
        *,
        base_url: str,
        api_key: str,
        payload: dict,
        provider: str,
        premium: bool = False,
    ) -> dict | str:
        """
        Make one chat-completions call with up to 3 retries on transient errors.
        Returns the parsed JSON dict on success, or an error string on failure.
        """
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }

        last_error = ""
        url = f"{base_url}/chat/completions"
        logger.info("API call â†’ %s | model: %s | provider: %s",
                     url, payload.get("model", "?"), provider)

        for attempt in range(3):
            try:
                async with self.session.post(
                    url,
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=90),
                ) as resp:
                    if resp.status == 200:
                        return await resp.json()

                    body = await resp.text()
                    logger.error("API error %d from %s (attempt %d): %s",
                                 resp.status, provider, attempt + 1, body[:500])

                    if resp.status == 429:
                        last_error = f"Rate-limited (429): {body[:200]}"
                        wait = int(resp.headers.get("Retry-After", 2 ** (attempt + 1)))
                        logger.warning("Rate-limited (%s, attempt %d). Waiting %dsâ€¦",
                                       provider, attempt + 1, wait)
                        if premium and len(VOID_API_KEYS) > 1:
                            api_key = random.choice(VOID_API_KEYS)
                            headers["Authorization"] = f"Bearer {api_key}"
                        await asyncio.sleep(wait)
                        continue

                    if resp.status >= 500:
                        last_error = f"Server error ({resp.status}): {body[:200]}"
                        logger.warning("Server error %d (attempt %d). Retryingâ€¦",
                                       resp.status, attempt + 1)
                        await asyncio.sleep(2 ** attempt)
                        continue

                    last_error = f"API {resp.status}: {body[:300]}"
                    logger.error("Non-retryable error from %s: %s", provider, last_error)
                    break

            except asyncio.TimeoutError:
                last_error = "Request timed out (90s)"
                logger.warning("Timeout (attempt %d) for %s", attempt + 1, provider)
                await asyncio.sleep(2 ** attempt)
            except aiohttp.ClientError as exc:
                last_error = str(exc)
                logger.warning("Connection error (attempt %d): %s", attempt + 1, exc)
                await asyncio.sleep(2 ** attempt)

        return f"âš ï¸ Sorry, I couldn't reach the AI service right now. ({last_error})"

    # â”€â”€â”€ Chat Completion with Text-Based Tool Detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def chat(
        self,
        messages: list[dict],
        *,
        premium: bool = False,
        temperature: float = 0.7,
        max_tokens: int = 2048,
        use_tools: bool = False,
    ) -> tuple[str, list[str]]:
        """
        Chat completion with text-based tool detection.
        Returns (response_text, image_urls).

        The model can include <<SEARCH>>query<</SEARCH>> or <<IMAGE>>prompt<</IMAGE>>
        tags in its response. This method detects them, executes the tools, and
        (for search) re-calls the model with results so it can write a final answer.
        """
        if premium:
            if not VOID_API_KEYS:
                return ("âš ï¸ Premium chat is not configured. "
                        "Set `VOID_API_KEYS` in your environment."), []
            api_key = random.choice(VOID_API_KEYS)
            base_url = VOID_BASE_URL
            model = VOID_MODEL
            provider = "VoidAI"
        else:
            if not NVIDIA_API_KEY:
                return ("âš ï¸ Standard chat is not configured. "
                        "Set `NVIDIA_API_KEY` in your environment."), []
            api_key = NVIDIA_API_KEY
            base_url = NVIDIA_BASE_URL
            model = NVIDIA_MODEL
            provider = "NVIDIA"

        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": False,
        }

        image_urls: list[str] = []

        # Tool loop: get response â†’ check for tool tags â†’ execute â†’ re-call if needed.
        for round_num in range(MAX_TOOL_ROUNDS + 1):
            result = await self._api_request(
                base_url=base_url,
                api_key=api_key,
                payload=payload,
                provider=provider,
                premium=premium,
            )

            # API error â€” bail out.
            if isinstance(result, str):
                return result, image_urls

            reply_text = result["choices"][0]["message"].get("content") or ""

            if not use_tools or round_num >= MAX_TOOL_ROUNDS:
                # Strip any leftover tags the model might have included.
                reply_text = _SEARCH_TAG_RE.sub("", reply_text)
                reply_text = _IMAGE_TAG_RE.sub("", reply_text)
                return reply_text.strip(), image_urls

            # --- Detect tool tags in the model's response ---
            search_match = _SEARCH_TAG_RE.search(reply_text)
            image_match = _IMAGE_TAG_RE.search(reply_text)

            if not search_match and not image_match:
                # No tools requested â€” return as-is.
                return reply_text.strip(), image_urls

            # --- Execute IMAGE tool (doesn't need a re-call) ---
            if image_match:
                img_prompt = image_match.group(1).strip()
                logger.info("Tool tag detected: <<IMAGE>> %r", img_prompt[:80])
                url = await self.generate_image(img_prompt, premium=premium)
                if url and url.startswith("http"):
                    image_urls.append(url)
                    logger.info("  â†’ Image generated: %s", url)
                else:
                    logger.warning("  â†’ Image generation failed for: %s", img_prompt[:80])
                # Remove the IMAGE tag from the text the user sees.
                reply_text = _IMAGE_TAG_RE.sub("", reply_text).strip()

            # --- Execute SEARCH tool (needs a re-call for the model to use results) ---
            if search_match:
                search_query = search_match.group(1).strip()
                logger.info("Tool tag detected: <<SEARCH>> %r", search_query)
                search_results = await self.web_search(search_query, premium=premium)

                # Clean the tags out of the assistant's message.
                clean_reply = _SEARCH_TAG_RE.sub("", reply_text)
                clean_reply = _IMAGE_TAG_RE.sub("", clean_reply).strip()

                # Add the assistant's (cleaned) message + search results to history.
                messages.append({"role": "assistant", "content": clean_reply})
                messages.append({
                    "role": "system",
                    "content": SEARCH_INJECTION_PROMPT.format(results=search_results),
                })
                payload["messages"] = messages
                logger.info("  â†’ Search done, re-calling %s for final answerâ€¦", provider)
                continue  # Loop back to get the model's final answer.

            # If we only had IMAGE (no search), return now.
            return reply_text.strip(), image_urls

        # Safety fallback.
        return "âš ï¸ I ran into an issue processing your request. Please try again.", image_urls

    # â”€â”€â”€ Web Search (Old-LLM API â†’ Gemini with built-in search) â”€â”€â”€
    async def web_search(self, query: str, *, premium: bool = False) -> str:
        """
        Call the Old-LLM API which routes to Gemini models with built-in
        web search. Premium gets Gemini-3-Pro, Standard gets Gemini-3-Flash.
        Returns the search-augmented response text.
        """
        if not OLD_LLM_KEY:
            return "âš ï¸ Web search is not configured. Set `OLD_LLM_KEY` in your environment."

        model = SEARCH_MODEL_PREMIUM if premium else SEARCH_MODEL_STANDARD
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": query}],
            "stream": False,
        }
        headers = {
            "Authorization": f"Bearer {OLD_LLM_KEY}",
            "Content-Type": "application/json",
        }

        for attempt in range(2):
            try:
                async with self.session.post(
                    OLD_LLM_BASE_URL,
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=60),
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        content = data["choices"][0]["message"]["content"]
                        if content and content.strip():
                            return content
                        return "Search returned no results."

                    body = await resp.text()
                    logger.warning("Old-LLM search error %d (attempt %d): %s",
                                   resp.status, attempt + 1, body[:200])
                    if resp.status >= 500:
                        await asyncio.sleep(2 ** attempt)
                        continue
                    break

            except asyncio.TimeoutError:
                logger.warning("Search timeout (attempt %d)", attempt + 1)
                await asyncio.sleep(2)
            except aiohttp.ClientError as exc:
                logger.warning("Search connection error: %s", exc)
                await asyncio.sleep(2)

        return "âš ï¸ Web search failed. Proceeding with internal knowledge."

    # â”€â”€â”€ Image Generation (Airforce API â†’ Flux models) â”€â”€â”€
    async def generate_image(
        self,
        prompt: str,
        *,
        premium: bool = False,
        width: int = 1024,
        height: int = 1024,
        aspect: str = "1:1",
        resolution: str = "1k",
    ) -> Optional[str]:
        """
        Generate an image using the Airforce API.
        Premium â†’ Flux-2-Flex (aspect ratio + resolution controls).
        Standard â†’ Flux-2-Klein-9B (width/height controls).
        Returns the image URL or None on failure.
        """
        if not AIR_API_KEYS:
            return None

        key = random.choice(AIR_API_KEYS)
        headers = {
            "Authorization": f"Bearer {key}",
            "Content-Type": "application/json",
        }

        if premium:
            payload = {
                "model": IMAGE_MODEL_PREMIUM,
                "prompt": prompt,
                "aspectRatio": aspect,
                "resolution": resolution,
                "sse": True,
            }
        else:
            payload = {
                "model": IMAGE_MODEL_STANDARD,
                "prompt": prompt,
                "width": width,
                "height": height,
                "sse": True,
            }

        try:
            async with self.session.post(
                AIR_BASE_URL,
                json=payload,
                headers=headers,
                timeout=aiohttp.ClientTimeout(total=120),
            ) as resp:
                if resp.status != 200:
                    body = await resp.text()
                    logger.error("Airforce image error %d: %s", resp.status, body[:300])
                    return None

                # The Airforce API streams SSE events. Parse them to find the URL.
                async for raw_line in resp.content:
                    line = raw_line.decode("utf-8", errors="replace").strip()
                    if not line or "[DONE]" in line:
                        continue
                    if line.startswith("data: "):
                        try:
                            data = json.loads(line[6:])
                            # Different response formats from Airforce:
                            if isinstance(data, dict):
                                if "url" in data:
                                    return data["url"]
                                if "data" in data and isinstance(data["data"], list):
                                    return data["data"][0].get("url")
                        except json.JSONDecodeError:
                            continue

                # If no SSE, try parsing the whole response as JSON.
                try:
                    text = await resp.text()
                    data = json.loads(text)
                    if "data" in data and isinstance(data["data"], list):
                        return data["data"][0].get("url")
                except Exception:
                    pass

        except asyncio.TimeoutError:
            logger.error("Image generation timed out")
        except aiohttp.ClientError as exc:
            logger.error("Image generation connection error: %s", exc)

        return None


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  CUSTOM COMMAND TREE  (global slash-command error handler)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
class OmniCommandTree(app_commands.CommandTree):
    async def on_error(
        self,
        interaction: discord.Interaction,
        error: app_commands.AppCommandError,
    ):
        if isinstance(error, app_commands.CommandOnCooldown):
            msg = f"â³ Cooldown active. Try again in **{error.retry_after:.1f}s**."
        elif isinstance(error, app_commands.MissingPermissions):
            msg = "ğŸ”’ You don't have permission to use this command."
        else:
            logger.error("Unhandled slash-command error:\n%s",
                         "".join(traceback.format_exception(type(error), error, error.__traceback__)))
            msg = "âŒ Something went wrong. The error has been logged."

        try:
            if interaction.response.is_done():
                await interaction.followup.send(msg, ephemeral=True)
            else:
                await interaction.response.send_message(msg, ephemeral=True)
        except discord.HTTPException:
            pass  # Interaction expired or was already handled.


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  BOT CLASS
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
class OmniBot(commands.Bot):
    def __init__(self) -> None:
        intents = discord.Intents.default()
        intents.message_content = True   # REQUIRED â€” enable in Developer Portal
        intents.members = True           # REQUIRED â€” enable in Developer Portal
        intents.presences = True         # enable in Developer Portal

        super().__init__(
            command_prefix=commands.when_mentioned_or("!"),
            intents=intents,
            help_command=None,
            tree_cls=OmniCommandTree,
        )
        self.session: aiohttp.ClientSession = None  # type: ignore[assignment]
        self.ai: AIEngine = None  # type: ignore[assignment]
        self.start_time: float = 0.0
        self._web_runner: web.AppRunner = None  # type: ignore[assignment]

    # â”€â”€ Lifecycle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def setup_hook(self) -> None:
        self.start_time = time.time()

        # Single shared aiohttp session â€” reused for every HTTP call.
        self.session = aiohttp.ClientSession()
        self.ai = AIEngine(self.session)

        # Async health-check server (replaces the old Flask keep-alive).
        web_app = web.Application()
        web_app.router.add_get("/", self._health)
        web_app.router.add_get("/health", self._health)
        self._web_runner = web.AppRunner(web_app)
        await self._web_runner.setup()
        site = web.TCPSite(self._web_runner, "0.0.0.0", PORT)
        await site.start()
        logger.info("Health-check server listening on :%d", PORT)

        # Sync slash commands globally.
        synced = await self.tree.sync()
        logger.info("Synced %d slash command(s).", len(synced))

    async def on_ready(self) -> None:
        logger.info("Logged in as %s (ID: %s)", self.user, self.user.id)
        logger.info("Connected to %d guild(s)", len(self.guilds))
        logger.info("Premium role: '%s'  |  VoidAI keys: %d  |  Airforce keys: %d",
                     PREMIUM_ROLE_NAME, len(VOID_API_KEYS), len(AIR_API_KEYS))
        await self.change_presence(
            status=discord.Status.online,
            activity=discord.Activity(
                type=discord.ActivityType.watching,
                name="Omni-Labs â€¢ /ask or @me",
            ),
        )

    async def close(self) -> None:
        if self._web_runner:
            await self._web_runner.cleanup()
        if self.session and not self.session.closed:
            await self.session.close()
        await super().close()

    # â”€â”€ Health Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def _health(self, _request: web.Request) -> web.Response:
        uptime = time.time() - self.start_time
        return web.json_response({
            "status": "healthy",
            "bot": str(self.user),
            "guilds": len(self.guilds),
            "latency_ms": round(self.latency * 1000, 1),
            "uptime_s": round(uptime, 1),
        })

    # â”€â”€ Core: Build messages & get AI response â”€â”€
    async def get_response(
        self,
        user_message: str,
        channel_id: int,
        *,
        author_name: str | None = None,
        premium: bool = False,
        force_search: bool = False,
    ) -> tuple[str, list[str]]:
        """
        The main AI pipeline. Returns (reply_text, image_urls).
        1. Check for search intent (keyword-based or force_search flag).
        2. Build message list: system prompt + cross-channel context + memory + user msg.
        3. Call the chat API with tool calling enabled.
        4. Save to memory with author tracking.
        """
        should_search = force_search or _has_search_intent(user_message)

        # --- System prompt ---
        system_content = SYSTEM_PROMPT

        # --- Add cross-channel context if not in main channel ---
        cross_channel = get_cross_channel_context(channel_id)
        if cross_channel:
            system_content += (
                "\n\n[Server Context â€” you are responding in a side channel, "
                "not the main bot channel. Here's recent activity elsewhere:]\n"
                + cross_channel
            )

        messages: list[dict] = [{"role": "system", "content": system_content}]

        # --- Web search (if explicitly triggered via keyword or flag) ---
        if should_search:
            search_results = await self.ai.web_search(user_message, premium=premium)
            messages.append({
                "role": "system",
                "content": SEARCH_INJECTION_PROMPT.format(results=search_results),
            })

        # --- Conversation history ---
        messages.extend(get_channel_history(channel_id))

        # --- Current user message ---
        messages.append({"role": "user", "content": user_message})

        # --- Call the AI with tool calling ---
        reply, image_urls = await self.ai.chat(
            messages, premium=premium, use_tools=True,
        )

        # --- Persist to memory with author tracking ---
        add_to_history(channel_id, "user", user_message, author=author_name)
        add_to_history(channel_id, "assistant", reply)

        return reply, image_urls

    # â”€â”€ Send a (possibly long) reply â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def send_reply(
        self,
        destination,
        text: str,
        *,
        reference: discord.Message | None = None,
    ) -> None:
        chunks = chunk_message(text)

        # If the response is absurdly long, send as a file.
        if len(chunks) > 5:
            buf = io.BytesIO(text.encode("utf-8"))
            file = discord.File(buf, filename="omni-response.txt")
            if isinstance(destination, discord.Interaction):
                await destination.followup.send(
                    "ğŸ“„ Response too long for chat â€” here's the full text:", file=file)
            else:
                await destination.send(
                    "ğŸ“„ Response too long for chat â€” here's the full text:",
                    file=file, reference=reference)
            return

        for i, chunk in enumerate(chunks):
            if isinstance(destination, discord.Interaction):
                await destination.followup.send(chunk)
            else:
                if i == 0:
                    await destination.send(chunk, reference=reference)
                else:
                    await destination.send(chunk)
            if i < len(chunks) - 1:
                await asyncio.sleep(0.4)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  CREATE THE BOT INSTANCE
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
bot = OmniBot()


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  EVENT: on_message  (Mentions & DMs)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
@bot.event
async def on_message(message: discord.Message) -> None:
    if message.author.bot:
        return

    is_dm = isinstance(message.channel, discord.DMChannel)
    is_mention = bot.user is not None and bot.user.mentioned_in(message) and not message.mention_everyone

    if not (is_dm or is_mention):
        await bot.process_commands(message)
        return

    # Clean the mention out of the text.
    content = message.content
    if bot.user:
        content = re.sub(rf"<@!?{bot.user.id}>", "", content).strip()

    if not content:
        await message.reply(
            "Hey there! ğŸ‘‹ Ask me anything, or try `/ask`, `/search`, or `/imagine`.")
        return

    # Mentions/DMs use the user's premium status (role-based).
    # In DMs, message.author is a User (no roles) â†’ defaults to standard.
    is_premium = has_premium_role(message.author)

    async with message.channel.typing():
        reply, image_urls = await bot.get_response(
            content,
            channel_id=message.channel.id,
            author_name=message.author.display_name,
            premium=is_premium,
        )

    await bot.send_reply(message.channel, reply, reference=message)

    # If the model generated images via tool calls, send them.
    for url in image_urls:
        embed = discord.Embed(color=discord.Color.purple())
        embed.set_image(url=url)
        embed.set_footer(text="ğŸ¨ Generated by Omni-Bot")
        await message.channel.send(embed=embed)

    await bot.process_commands(message)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  PREFIX COMMAND: !clear
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
@bot.command(name="clear")
async def cmd_clear(ctx: commands.Context) -> None:
    """Clear this channel's conversation memory."""
    clear_channel_history(ctx.channel.id)
    await ctx.send("ğŸ§¹ This channel's conversation memory has been cleared.")


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  SLASH COMMANDS
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# â”€â”€ /ask â€” Standard chat (Kimi-K2) â”€â”€
@bot.tree.command(name="ask", description="Ask Omni-Bot a question (Standard â€” Kimi-K2)")
@app_commands.describe(
    question="Your question or prompt",
    search="Enable real-time web search",
)
async def slash_ask(
    interaction: discord.Interaction,
    question: str,
    search: bool = False,
) -> None:
    await interaction.response.defer()

    is_premium = has_premium_role(interaction.user)

    reply, image_urls = await bot.get_response(
        question,
        channel_id=interaction.channel.id,
        author_name=interaction.user.display_name,
        premium=is_premium,
        force_search=search,
    )

    tier = "Premium âœ¨" if is_premium else "Standard"
    search_tag = " â€¢ ğŸŒ Web Search" if (search or _has_search_intent(question)) else ""

    embed = discord.Embed(
        description=reply[:4096],
        color=discord.Color.gold() if is_premium else discord.Color.blue(),
    )
    embed.set_author(
        name="Omni-Bot",
        icon_url=bot.user.display_avatar.url if bot.user else None,
    )
    # If the model generated an image, attach the first one to the embed.
    if image_urls:
        embed.set_image(url=image_urls[0])
    embed.set_footer(text=f"{tier}{search_tag}")
    await interaction.followup.send(embed=embed)

    # Send any extra images as separate embeds.
    for url in image_urls[1:]:
        extra = discord.Embed(color=discord.Color.purple())
        extra.set_image(url=url)
        await interaction.followup.send(embed=extra)


# â”€â”€ /ask_pro â€” Premium chat (GPT-5.2, Premium role only) â”€â”€
@bot.tree.command(name="ask_pro", description="Ask Omni-Bot Pro (GPT-5.2 â€” Premium Access role required)")
@app_commands.describe(
    question="Your question or prompt",
    search="Enable real-time web search",
)
async def slash_ask_pro(
    interaction: discord.Interaction,
    question: str,
    search: bool = False,
) -> None:
    # Only users with the Premium Access role can use /ask_pro.
    if not has_premium_role(interaction.user):
        await interaction.response.send_message(
            f"ğŸ”’ You need the **{PREMIUM_ROLE_NAME}** role to use `/ask_pro`.\n"
            "Use `/ask` for standard access, or contact the server owner for Premium!",
            ephemeral=True,
        )
        return

    await interaction.response.defer()

    reply, image_urls = await bot.get_response(
        question,
        channel_id=interaction.channel.id,
        author_name=interaction.user.display_name,
        premium=True,
        force_search=search,
    )

    search_tag = " â€¢ ğŸŒ Web Search" if (search or _has_search_intent(question)) else ""

    embed = discord.Embed(
        description=reply[:4096],
        color=discord.Color.gold(),
    )
    embed.set_author(
        name="Omni-Bot Pro âœ¨",
        icon_url=bot.user.display_avatar.url if bot.user else None,
    )
    if image_urls:
        embed.set_image(url=image_urls[0])
    embed.set_footer(text=f"GPT-5.2{search_tag}")
    await interaction.followup.send(embed=embed)

    for url in image_urls[1:]:
        extra = discord.Embed(color=discord.Color.purple())
        extra.set_image(url=url)
        await interaction.followup.send(embed=extra)


# â”€â”€ /search â€” Dedicated web search â”€â”€
@bot.tree.command(name="search", description="Search the web and get an AI-synthesized answer")
@app_commands.describe(query="What to search for")
async def slash_search(interaction: discord.Interaction, query: str) -> None:
    await interaction.response.defer()

    is_premium = has_premium_role(interaction.user)

    reply, image_urls = await bot.get_response(
        query,
        channel_id=interaction.channel.id,
        author_name=interaction.user.display_name,
        premium=is_premium,
        force_search=True,
    )

    embed = discord.Embed(
        title=f"ğŸŒ Search: {query[:200]}",
        description=reply[:4096],
        color=discord.Color.green(),
    )
    embed.set_footer(
        text=f"Powered by {'Gemini-3-Pro' if is_premium else 'Gemini-3-Flash'} + Omni-Bot")
    await interaction.followup.send(embed=embed)


# â”€â”€ /image â€” Standard image generation (Flux-2-Klein) â”€â”€
@bot.tree.command(name="image", description="Generate an AI image (Standard â€” Flux-Klein)")
@app_commands.describe(
    prompt="Describe the image you want",
    width="Image width in pixels (default 1024)",
    height="Image height in pixels (default 1024)",
)
async def slash_image(
    interaction: discord.Interaction,
    prompt: str,
    width: int = 1024,
    height: int = 1024,
) -> None:
    await interaction.response.defer()

    url = await bot.ai.generate_image(
        prompt, premium=False, width=width, height=height)

    if url and url.startswith("http"):
        embed = discord.Embed(
            title="ğŸ¨ Omni-Labs Image Gen",
            description=f"**Prompt:** {prompt[:300]}",
            color=discord.Color.purple(),
        )
        embed.set_image(url=url)
        embed.set_footer(text=f"Model: Flux-2-Klein â€¢ {width}Ã—{height}")
        await interaction.followup.send(embed=embed)
    else:
        await interaction.followup.send(
            "âŒ Image generation failed. Please try again or check that "
            "`AIR_API_KEYS` is configured.",
            ephemeral=True,
        )


# â”€â”€ /image_pro â€” Premium image generation (Flux-2-Flex, Premium role only) â”€â”€
@bot.tree.command(name="image_pro", description="Generate Pro Images (Flux-2-Flex â€” Premium Access role required)")
@app_commands.describe(
    prompt="Describe the image you want",
    aspect="Aspect ratio",
    res="Output resolution",
)
@app_commands.choices(
    aspect=[
        app_commands.Choice(name="1:1 (Square)", value="1:1"),
        app_commands.Choice(name="16:9 (Landscape)", value="16:9"),
        app_commands.Choice(name="9:16 (Portrait)", value="9:16"),
        app_commands.Choice(name="4:3 (Classic)", value="4:3"),
        app_commands.Choice(name="3:4 (Tall)", value="3:4"),
    ],
    res=[
        app_commands.Choice(name="1K", value="1k"),
        app_commands.Choice(name="2K", value="2k"),
    ],
)
async def slash_image_pro(
    interaction: discord.Interaction,
    prompt: str,
    aspect: str = "1:1",
    res: str = "1k",
) -> None:
    # Only users with the Premium Access role can use /image_pro.
    if not has_premium_role(interaction.user):
        await interaction.response.send_message(
            f"ğŸ”’ You need the **{PREMIUM_ROLE_NAME}** role to use `/image_pro`.\n"
            "Use `/image` for standard quality, or contact the server owner for Premium!",
            ephemeral=True,
        )
        return

    await interaction.response.defer()

    url = await bot.ai.generate_image(
        prompt, premium=True, aspect=aspect, resolution=res)

    if url and url.startswith("http"):
        embed = discord.Embed(
            title="ğŸš€ Omni-Labs Pro Image",
            description=f"**Prompt:** {prompt[:300]}",
            color=discord.Color.gold(),
        )
        embed.set_image(url=url)
        embed.set_footer(text=f"Model: Flux-2-Flex â€¢ Aspect: {aspect} â€¢ Res: {res}")
        await interaction.followup.send(embed=embed)
    else:
        await interaction.followup.send(
            "âŒ Pro image generation failed. Please try again.",
            ephemeral=True,
        )


# â”€â”€ /status â€” Check tier â”€â”€
@bot.tree.command(name="status", description="Check your Omni-Bot subscription tier")
async def slash_status(interaction: discord.Interaction) -> None:
    is_prem = has_premium_role(interaction.user)
    if is_prem:
        embed = discord.Embed(
            title="ğŸŒŸ Premium Tier",
            description=(
                f"**Chat Model:** `{VOID_MODEL}`\n"
                f"**Search Model:** `{SEARCH_MODEL_PREMIUM}`\n"
                f"**Image Model:** `{IMAGE_MODEL_PREMIUM}`\n\n"
                f"âœ… You have the **{PREMIUM_ROLE_NAME}** role â€” "
                "enjoy the most powerful models!"
            ),
            color=discord.Color.gold(),
        )
    else:
        embed = discord.Embed(
            title="ğŸ”¹ Standard Tier",
            description=(
                f"**Chat Model:** `{NVIDIA_MODEL.split('/')[-1]}`\n"
                f"**Search Model:** `{SEARCH_MODEL_STANDARD}`\n"
                f"**Image Model:** `{IMAGE_MODEL_STANDARD}`\n\n"
                "Use `/ask_pro` to access GPT-5.2 for individual questions.\n"
                f"Get the **{PREMIUM_ROLE_NAME}** role for permanent upgrades!"
            ),
            color=discord.Color.blue(),
        )
    await interaction.response.send_message(embed=embed, ephemeral=True)


# â”€â”€ /clear â€” Clear memory â”€â”€
@bot.tree.command(name="clear", description="Clear this channel's conversation memory")
async def slash_clear(interaction: discord.Interaction) -> None:
    clear_channel_history(interaction.channel.id)
    await interaction.response.send_message(
        "ğŸ§¹ This channel's conversation memory has been cleared.", ephemeral=True)


# â”€â”€ /donate â€” Support link â”€â”€
@bot.tree.command(name="donate", description="Support Omni-Labs creators")
async def slash_donate(interaction: discord.Interaction) -> None:
    embed = discord.Embed(
        title="ğŸ’– Support Omni-Labs",
        description=(
            "Love what we're building? Help us keep the servers running and "
            "develop new features!\n\n"
            "**â†’ [Donate on Poe](https://poe.com/Donoz)**\n\n"
            "Every bit helps. Thank you! ğŸ™"
        ),
        color=discord.Color.pink(),
    )
    await interaction.response.send_message(embed=embed)


# â”€â”€ /help â€” Full help menu â”€â”€
@bot.tree.command(name="help", description="Learn how to use Omni-Bot")
async def slash_help(interaction: discord.Interaction) -> None:
    embed = discord.Embed(
        title="ğŸ“– Omni-Bot Help â€” by Omni-Labs",
        description="Your AI-powered assistant, right here in Discord.",
        color=discord.Color.blurple(),
    )
    embed.add_field(
        name="ğŸ’¬ Chat",
        value=(
            "**@mention me** or **DM me** to chat naturally.\n"
            f"`/ask <question>` â€” Standard chat (Kimi-K2).\n"
            f"`/ask_pro <question>` â€” **Pro chat (GPT-5.2)** â€” requires **{PREMIUM_ROLE_NAME}** role.\n"
            "I remember each channel's conversation thread â€” use `/clear` to reset this channel's memory."
        ),
        inline=False,
    )
    embed.add_field(
        name="ğŸŒ Web Search",
        value=(
            "`/search <query>` â€” Search + AI synthesis (auto-detects your tier).\n"
            "`/ask <question> search:True` â€” Standard search for any question.\n"
            "`/ask_pro <question> search:True` â€” Pro search (GPT-5.2 + Gemini-Pro).\n"
            "**Keywords that auto-trigger search:** latest, news, who is, what happened, today, recent, etc."
        ),
        inline=False,
    )
    embed.add_field(
        name="ğŸ¨ Image Generation",
        value=(
            "`/image <prompt>` â€” Standard quality (Flux-Klein) â€” everyone.\n"
            f"`/image_pro <prompt>` â€” **Pro quality (Flux-2-Flex)** with aspect & resolution â€” requires **{PREMIUM_ROLE_NAME}** role."
        ),
        inline=False,
    )
    embed.add_field(
        name="âš™ï¸ Utilities",
        value=(
            "`/clear` â€” Wipe your conversation memory.\n"
            "`/status` â€” Check your tier & models.\n"
            "`/donate` â€” Support Omni-Labs.\n"
            "`!clear` â€” Prefix command version of /clear."
        ),
        inline=False,
    )
    embed.set_footer(
        text=f"Standard: Kimi-K2  â€¢  Premium ({PREMIUM_ROLE_NAME} role): GPT-5.2")
    await interaction.response.send_message(embed=embed, ephemeral=True)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  GLOBAL ERROR HANDLER (prefix commands)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
@bot.event
async def on_command_error(ctx: commands.Context, error: commands.CommandError) -> None:
    if isinstance(error, commands.CommandNotFound):
        return
    if isinstance(error, commands.MissingRequiredArgument):
        await ctx.send(f"âš ï¸ Missing argument: `{error.param.name}`")
    elif isinstance(error, commands.MissingPermissions):
        await ctx.send("ğŸ”’ You don't have permission to do that.")
    else:
        logger.error("Prefix command error:\n%s",
                     "".join(traceback.format_exception(type(error), error, error.__traceback__)))
        await ctx.send("âŒ Something went wrong. The error has been logged.")


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  ENTRY POINT
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
if __name__ == "__main__":
    if not DISCORD_TOKEN:
        logger.critical("DISCORD_BOT_TOKEN is not set! Add it to your Koyeb environment variables.")
        raise SystemExit(1)

    missing = []
    if not NVIDIA_API_KEY:
        missing.append("NVIDIA_API_KEY (Standard chat won't work)")
    if not VOID_API_KEYS:
        missing.append("VOID_API_KEYS (Premium chat won't work)")
    if not OLD_LLM_KEY:
        missing.append("OLD_LLM_KEY (Web search won't work)")
    if not AIR_API_KEYS:
        missing.append("AIR_API_KEYS (Image generation won't work)")
    if missing:
        logger.warning("Missing optional env vars:\n  â€¢ %s", "\n  â€¢ ".join(missing))

    logger.info("Starting Omni-Botâ€¦")
    bot.run(DISCORD_TOKEN, log_handler=None)
